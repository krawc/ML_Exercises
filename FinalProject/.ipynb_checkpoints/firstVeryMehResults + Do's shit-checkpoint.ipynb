{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split #to split in train and test set\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score #BONUS: to tune parameters using cross-validation\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/konradkrawczyk/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data is a bunch of columns with different features.\n",
    "#1 - month\n",
    "#3 - day of the week\n",
    "#4 - airline\n",
    "#7 - departure airport\n",
    "#9 - departure time\n",
    "#17 - distance\n",
    "#and target:\n",
    "#22 - arrival delay time || 0 => no relevant delay; 1 => some delay; 2 => major delay\n",
    "\n",
    "my_data = pd.read_csv('trimmedandnew.csv', usecols=[1,3,4,7,9,17,22])\n",
    "\n",
    "# randomizes data\n",
    "my_data = my_data.sample(frac=1)\n",
    "\n",
    "# Create a set of dummy variables from the variable. \n",
    "# They say all over the internets that this is how you're supposed to handle categorical vars like strings etc.\n",
    "df_dummies = pd.get_dummies(my_data.iloc[:,[2,3]])\n",
    "\n",
    "#convert hours and minutes to just hours\n",
    "for index, row in my_data.iterrows():\n",
    "    hour = math.floor(int(row[5])/100)\n",
    "    minutes = int(row[5])/100 - hour\n",
    "    if minutes < .3:\n",
    "        row[5] = hour\n",
    "    else:\n",
    "        row[5] = hour + 1\n",
    "\n",
    "#get values for the target (delay on arrival)\n",
    "yVal = np.array(my_data.iloc[:,[6]]).reshape(shape(my_data)[0],)\n",
    "y = []\n",
    "\n",
    "#delay has 4 values: on time (0), slight delay (1), medium delay (2) significant delay (3)\n",
    "for value in yVal:\n",
    "    if value <=5:\n",
    "        tgt = 0\n",
    "    elif value <= 45:\n",
    "        tgt = 1        \n",
    "    else: \n",
    "        tgt = 2\n",
    "    y.append(tgt)\n",
    "\n",
    "\n",
    "#remove targets and columns that were converted into dummy variables\n",
    "my_data = my_data.drop(my_data.columns[[2, 3, 6]], axis=1)\n",
    "\n",
    "#concat my_data and dummies and generate a np.ndarray of features\n",
    "df_new = pd.concat([my_data, df_dummies], axis=1)\n",
    "X = df_new.values\n",
    "\n",
    "# Scale X\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "#split the data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379545, 340)\n"
     ]
    }
   ],
   "source": [
    "print(shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------RANDOM FOREST:------------------------\n",
      "\n",
      "Cross-Validation: means & stds for given\n"
     ]
    }
   ],
   "source": [
    "def forest():\n",
    "    \n",
    "    #prepare c-values for cross validation\n",
    "    cVal = [3, 6, 9, 12]\n",
    "    \n",
    "    print('------------------------RANDOM FOREST:------------------------')\n",
    "    print('');\n",
    "    print('Cross-Validation: means & stds for given');\n",
    "    #define the classifier\n",
    "    cv_forestClass = RandomForestClassifier(class_weight=\"balanced\", n_estimators=80, max_features=0.3, max_depth=8)\n",
    "    #use GridSearchCV to generate the best c-value for a classifier, from the cVal array\n",
    "    cv_forest = GridSearchCV(estimator=cv_forestClass, param_grid = dict(min_samples_split=cVal), cv=10, scoring='accuracy')\n",
    "    #fit the data\n",
    "    cv_forest.fit(X_train, y_train)\n",
    "    #print the mean and s.dev. scores for every c-value for comparison\n",
    "    means_cv_forest = cv_forest.cv_results_['mean_test_score']\n",
    "    stds_cv_forest = cv_forest.cv_results_['std_test_score']\n",
    "    \n",
    "    #plot the mean accuracies for logistic regression CV\n",
    "    ax1 = plt.subplot(\"211\")\n",
    "    ax1.set_title(\"Average results for random forest CV\")\n",
    "    ax1.set_ylabel('avg accuracy in CV')\n",
    "    ax1.set_xlabel('regularization parameter')\n",
    "    ax1.plot(cVal, means_cv_forest)\n",
    "    print()\n",
    "    \n",
    "    #get the best c-value from grid search\n",
    "    best = cv_forest.best_params_['min_samples_split']\n",
    "    #define logistic regression using the best value\n",
    "    cv_forestBest = RandomForestClassifier(min_samples_split=best, class_weight=\"balanced\", n_estimators=80, max_features=0.3, max_depth=8)\n",
    "    #fit the training data\n",
    "    cv_forestBest.fit(X_train, y_train)\n",
    "    #get the estimates\n",
    "    predicted = cv_forestBest.predict(X_test)\n",
    "    \n",
    "    print('Best score: {}'.format(best))\n",
    "    print()\n",
    "    print('Classification report for the best c-parameter (test set):')\n",
    "    print(classification_report(y_test, predicted))\n",
    "    print()\n",
    "    print('Confusion matrix for the best c-parameter (test set):')\n",
    "    print(metrics.confusion_matrix(y_test, predicted))\n",
    "    \n",
    "forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------LOGISTIC REGRESSION:------------------------\n",
      "\n",
      "Cross-Validation: means & stds for given c-values\n",
      "\n",
      "Best score: 0.0001\n",
      "\n",
      "Classification report for the best c-parameter (train set):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.95      0.87     45408\n",
      "          1       0.21      0.01      0.03      6063\n",
      "          2       0.20      0.10      0.13      5958\n",
      "\n",
      "avg / total       0.68      0.76      0.70     57429\n",
      "\n",
      "\n",
      "Confusion matrix for the best c-parameter (test set):\n",
      "[[43225   263  1920]\n",
      " [ 5570    90   403]\n",
      " [ 5287    73   598]]\n",
      "\n",
      "Classification report for the best c-parameter (test set):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.95      0.87     11315\n",
      "          1       0.23      0.01      0.03      1527\n",
      "          2       0.22      0.11      0.15      1516\n",
      "\n",
      "avg / total       0.68      0.76      0.70     14358\n",
      "\n",
      "\n",
      "Confusion matrix for the best c-parameter (test set):\n",
      "[[10771    50   494]\n",
      " [ 1400    21   106]\n",
      " [ 1327    19   170]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAACgCAYAAAAmR+roAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnGsWTyTOOeeaxROJc865Zvl/ARMGgQ4NZ+8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ab03a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logRegr():\n",
    "    \n",
    "    #prepare c-values for cross validation\n",
    "    cVal = [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 0.5, 1.]\n",
    "    \n",
    "    print('------------------------LOGISTIC REGRESSION:------------------------')\n",
    "    print('');\n",
    "    print('Cross-Validation: means & stds for given c-values');\n",
    "    #define the classifier\n",
    "    cv_regClass = LogisticRegression(class_weight=\"balanced\")\n",
    "    #use GridSearchCV to generate the best c-value for a classifier, from the cVal array\n",
    "    cv_reg = GridSearchCV(estimator=cv_regClass, param_grid = dict(C=cVal), cv=10, scoring='accuracy')\n",
    "    #fit the data\n",
    "    cv_reg.fit(X_train, y_train)\n",
    "    #print the mean and s.dev. scores for every c-value for comparison\n",
    "    means_cv_reg = cv_reg.cv_results_['mean_test_score']\n",
    "    stds_cv_reg = cv_reg.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means_cv_reg, stds_cv_reg, cv_reg.cv_results_['params']):\n",
    "        #print(\"Mean: %0.5f | Standard Deviation:(+/-%0.03f) | for %r\" % (mean, std * 2, params))\n",
    "    #print()\n",
    "    \n",
    "    #plot the mean accuracies for logistic regression CV\n",
    "    ax1 = plt.subplot(\"211\")\n",
    "    ax1.set_title(\"Average results for logistic regression CV\")\n",
    "    ax1.set_ylabel('avg accuracy in CV')\n",
    "    ax1.set_xlabel('regularization parameter')\n",
    "    ax1.plot(cVal, means_cv_reg)\n",
    "    print()\n",
    "    \n",
    "    #get the best c-value from grid search\n",
    "    best = cv_reg.best_params_['C']\n",
    "    #define logistic regression using the best value\n",
    "    cv_regBest = LogisticRegression(C=best, class_weight=\"balanced\")\n",
    "    #fit the training data\n",
    "    cv_regBest.fit(X_train, y_train)\n",
    "    #get the estimates\n",
    "    predictedtrain = cv_regBest.predict(X_train)\n",
    "    predictedtest = cv_regBest.predict(X_test)\n",
    "    \n",
    "    print('Best score: {}'.format(best))\n",
    "    print()\n",
    "    print('Classification report for the best c-parameter (train set):')\n",
    "    print(classification_report(y_train, predictedtrain))\n",
    "    print()\n",
    "    print('Confusion matrix for the best c-parameter (test set):')\n",
    "    print(metrics.confusion_matrix(y_train, predictedtrain))\n",
    "    print()\n",
    "    print('Classification report for the best c-parameter (test set):')\n",
    "    print(classification_report(y_test, predictedtest))\n",
    "    print()\n",
    "    print('Confusion matrix for the best c-parameter (test set):')\n",
    "    print(metrics.confusion_matrix(y_test, predictedtest))\n",
    "    \n",
    "logRegr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------NEURAL NETWORK:------------------------\n",
      "\n",
      "Cross-Validation: means & stds for given\n"
     ]
    }
   ],
   "source": [
    "def mlp():\n",
    "    \n",
    "\n",
    "    #prepare c-values for cross validation\n",
    "    hidden = [(30,30,30), (80,80,80), (120,120,120)] # NOTE (2,) is a single layer with 2 nodes\n",
    "    \n",
    "    print('------------------------NEURAL NETWORK:------------------------')\n",
    "    print('');\n",
    "    print('Cross-Validation: means & stds for given');\n",
    "    #define the classifier\n",
    "    cv_mlpClass = MLPClassifier()\n",
    "    #use GridSearchCV to generate the best c-value for a classifier, from the cVal array\n",
    "    cv_mlp = GridSearchCV(estimator=cv_mlpClass, param_grid = dict(hidden_layer_sizes=hidden), cv=10, scoring='accuracy')\n",
    "    #fit the data\n",
    "    cv_mlp.fit(X_train, y_train)\n",
    "    #print the mean and s.dev. scores for every c-value for comparison\n",
    "    means_cv_mlp = cv_mlp.cv_results_['mean_test_score']\n",
    "    stds_cv_mlp = cv_mlp.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means_cv_reg, stds_cv_reg, cv_reg.cv_results_['params']):\n",
    "        #print(\"Mean: %0.5f | Standard Deviation:(+/-%0.03f) | for %r\" % (mean, std * 2, params))\n",
    "    #print()\n",
    "    \n",
    "    #plot the mean accuracies for logistic regression CV\n",
    "    ax1 = plt.subplot(\"211\")\n",
    "    ax1.set_title(\"Average results for logistic regression CV\")\n",
    "    ax1.set_ylabel('avg accuracy in CV')\n",
    "    ax1.set_xlabel('regularization parameter')\n",
    "    ax1.plot(hidden, means_cv_mlp)\n",
    "    print()\n",
    "    \n",
    "    #get the best c-value from grid search\n",
    "    best = cv_mlp.best_params_['hidden_layer_sizes']\n",
    "    #define logistic regression using the best value\n",
    "    cv_mlpBest = MLPClassifier(hidden_layer_sizes=best)\n",
    "    #fit the training data\n",
    "    cv_mlpBest.fit(X_train, y_train)\n",
    "    #get the estimates\n",
    "    predictedtrain = cv_mlpBest.predict(X_train)\n",
    "    predictedtest = cv_mlpBest.predict(X_test)\n",
    "    \n",
    "    print('Best score: {}'.format(best))\n",
    "    print()\n",
    "    print('Classification report for the best c-parameter (train set):')\n",
    "    print(classification_report(y_train, predictedtrain))\n",
    "    print()\n",
    "    print('Confusion matrix for the best c-parameter (train set):')\n",
    "    print(metrics.confusion_matrix(y_train, predictedtrain))\n",
    "    print('Classification report for the best c-parameter (test set):')\n",
    "    print(classification_report(y_test, predictedtest))\n",
    "    print()\n",
    "    print('Confusion matrix for the best c-parameter (test set):')\n",
    "    print(metrics.confusion_matrix(y_test, predictedtest))\n",
    "    \n",
    "#mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp():\n",
    "        \n",
    "    print('------------------------NEURAL NETWORK:------------------------')\n",
    "    print('');\n",
    "\n",
    "    #define logistic regression using the best value\n",
    "    cv_mlpBest = MLPClassifier(hidden_layer_sizes=(30,30,30), solver='adam', alpha=1e-4)  #fit the training data\n",
    "    cv_mlpBest.fit(X_train, y_train)\n",
    "    #get the estimates\n",
    "    predictedtrain = cv_mlpBest.predict(X_train)\n",
    "    print(metrics.confusion_matrix(y_train, predictedtrain))\n",
    "    print(classification_report(y_train, predictedtrain))\n",
    "    predictedtest = cv_mlpBest.predict(X_test)\n",
    "    print(metrics.confusion_matrix(y_test, predictedtest))\n",
    "    print(classification_report(y_test, predictedtest))\n",
    "mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_reg = RandomForestClassifier(min_samples_split=2, class_weight=\"balanced\", n_estimators=50, max_features=0.3, max_depth=8)\n",
    "forest_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_train,(forest_reg.predict(X_train))))\n",
    "print(classification_report(y_train,(forest_reg.predict(X_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,(forest_reg.predict(X_test))))\n",
    "print(classification_report(y_test,(forest_reg.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
